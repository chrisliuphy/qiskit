{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data shape: (20000, 1, 101, 2)\n",
      "labels shape: (20000,)\n"
     ]
    }
   ],
   "source": [
    "# 1. 加载数据\n",
    "with h5py.File('C:/Users/liusi/Desktop/research/transformer/dataset.h5', 'r') as f:\n",
    "    input_data = f['input_data'][:]  # 读取输入数据\n",
    "\n",
    "    # 检查labels是否为标量数据集\n",
    "    if f['labels'].shape == ():  # 如果是标量\n",
    "        labels = f['labels'][()]  # 读取单个标量值\n",
    "    else:\n",
    "        labels = f['labels'][:]  # 读取数组\n",
    "\n",
    "print(\"input_data shape:\", input_data.shape)\n",
    "print(\"labels shape:\", labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 创建自定义数据集\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = torch.FloatTensor(labels)  # 转换为浮点型\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# 3. 划分训练和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(input_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建Dataset对象\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "\n",
    "# 4. 创建DataLoader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=40, kernel_size=(2, 2), stride=1, padding=0), # 输出尺寸：(N, 40, H-1, W-1)\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 1), stride=(1, 1)) # 这个池化层可能不会改变尺寸，取决于实际需求\n",
    "        )\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=40, out_channels=1, kernel_size=(1, 1), stride=1, padding=0), # 输出尺寸：(N, 1, H-1, W-1)\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(1, 1), stride=(1, 1))  # 这个池化层可能不会改变尺寸，取决于实际需求\n",
    "        )\n",
    "        # 在此全连接层之前，需要知道上一层的输出尺寸\n",
    "        # 假设上一层的输出尺寸是 (1, H', W')\n",
    "        # 全连接层的输入尺寸将是 1 * H' * W'\n",
    "        self.fc1 = nn.Linear(1 * 100 * 1, 2)  # 全连接层有2个神经元\n",
    "        self.fc2 = nn.Linear(2, 1)  # 对于回归问题，输出层有1个神经元\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.cnn2(out)\n",
    "        out = out.view(out.size(0), -1)  # 展平\n",
    "        out = F.relu(self.fc1(out))  # 应用ReLU激活函数\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 40, 100, 1]             200\n",
      "       BatchNorm2d-2           [-1, 40, 100, 1]              80\n",
      "              ReLU-3           [-1, 40, 100, 1]               0\n",
      "         MaxPool2d-4           [-1, 40, 100, 1]               0\n",
      "            Conv2d-5            [-1, 1, 100, 1]              41\n",
      "       BatchNorm2d-6            [-1, 1, 100, 1]               2\n",
      "              ReLU-7            [-1, 1, 100, 1]               0\n",
      "         MaxPool2d-8            [-1, 1, 100, 1]               0\n",
      "            Linear-9                    [-1, 2]             202\n",
      "           Linear-10                    [-1, 1]               3\n",
      "================================================================\n",
      "Total params: 528\n",
      "Trainable params: 528\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.13\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 模型实例化\n",
    "num_classes = 5  # 类别数\n",
    "in_channel = 1   # 输入通道数\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN(num_classes=num_classes, in_channels=in_channel).to(device)\n",
    "summary(model, input_size=(in_channel, 101, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "# 使用均方误差损失函数（MSE）对于回归任务\n",
    "criterior = nn.MSELoss()\n",
    "# 或者使用平均绝对误差损失函数（MAE）\n",
    "# criterior = nn.L1Loss()\n",
    "# criterior = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/100, step 250/250, loss = 0.6233\n",
      "2/100, step 250/250, loss = 0.6441\n",
      "3/100, step 250/250, loss = 0.4406\n",
      "4/100, step 250/250, loss = 0.3793\n",
      "5/100, step 250/250, loss = 0.5811\n",
      "6/100, step 250/250, loss = 0.3985\n",
      "7/100, step 250/250, loss = 0.4840\n",
      "8/100, step 250/250, loss = 0.4693\n",
      "9/100, step 250/250, loss = 0.5658\n",
      "10/100, step 250/250, loss = 0.5249\n",
      "11/100, step 250/250, loss = 0.5683\n",
      "12/100, step 250/250, loss = 0.4525\n",
      "13/100, step 250/250, loss = 0.4835\n",
      "14/100, step 250/250, loss = 0.5239\n",
      "15/100, step 250/250, loss = 0.5277\n",
      "16/100, step 250/250, loss = 0.4825\n",
      "17/100, step 250/250, loss = 0.3460\n",
      "18/100, step 250/250, loss = 0.3615\n",
      "19/100, step 250/250, loss = 0.5871\n",
      "20/100, step 250/250, loss = 0.5903\n",
      "21/100, step 250/250, loss = 0.6963\n",
      "22/100, step 250/250, loss = 0.6650\n",
      "23/100, step 250/250, loss = 0.4868\n",
      "24/100, step 250/250, loss = 0.5556\n",
      "25/100, step 250/250, loss = 0.6523\n",
      "26/100, step 250/250, loss = 0.4807\n",
      "27/100, step 250/250, loss = 0.6556\n",
      "28/100, step 250/250, loss = 0.4932\n",
      "29/100, step 250/250, loss = 0.5429\n",
      "30/100, step 250/250, loss = 0.5271\n",
      "31/100, step 250/250, loss = 0.4714\n",
      "32/100, step 250/250, loss = 0.5463\n",
      "33/100, step 250/250, loss = 0.4525\n",
      "34/100, step 250/250, loss = 0.5933\n",
      "35/100, step 250/250, loss = 0.5369\n",
      "36/100, step 250/250, loss = 0.5305\n",
      "37/100, step 250/250, loss = 0.4650\n",
      "38/100, step 250/250, loss = 0.4966\n",
      "39/100, step 250/250, loss = 0.3712\n",
      "40/100, step 250/250, loss = 0.5214\n",
      "41/100, step 250/250, loss = 0.4213\n",
      "42/100, step 250/250, loss = 0.4401\n",
      "43/100, step 250/250, loss = 0.5275\n",
      "44/100, step 250/250, loss = 0.4650\n",
      "45/100, step 250/250, loss = 0.5962\n",
      "46/100, step 250/250, loss = 0.4401\n",
      "47/100, step 250/250, loss = 0.5087\n",
      "48/100, step 250/250, loss = 0.5086\n",
      "49/100, step 250/250, loss = 0.4495\n",
      "50/100, step 250/250, loss = 0.4464\n",
      "51/100, step 250/250, loss = 0.5679\n",
      "52/100, step 250/250, loss = 0.5618\n",
      "53/100, step 250/250, loss = 0.6525\n",
      "54/100, step 250/250, loss = 0.3992\n",
      "55/100, step 250/250, loss = 0.4277\n",
      "56/100, step 250/250, loss = 0.5212\n",
      "57/100, step 250/250, loss = 0.4961\n",
      "58/100, step 250/250, loss = 0.4807\n",
      "59/100, step 250/250, loss = 0.4902\n",
      "60/100, step 250/250, loss = 0.5743\n",
      "61/100, step 250/250, loss = 0.6274\n",
      "62/100, step 250/250, loss = 0.3900\n",
      "63/100, step 250/250, loss = 0.4993\n",
      "64/100, step 250/250, loss = 0.4277\n",
      "65/100, step 250/250, loss = 0.3806\n",
      "66/100, step 250/250, loss = 0.6368\n",
      "67/100, step 250/250, loss = 0.4836\n",
      "68/100, step 250/250, loss = 0.4243\n",
      "69/100, step 250/250, loss = 0.5651\n",
      "70/100, step 250/250, loss = 0.4962\n",
      "71/100, step 250/250, loss = 0.5585\n",
      "72/100, step 250/250, loss = 0.3897\n",
      "73/100, step 250/250, loss = 0.4277\n",
      "74/100, step 250/250, loss = 0.4277\n",
      "75/100, step 250/250, loss = 0.3774\n",
      "76/100, step 250/250, loss = 0.4152\n",
      "77/100, step 250/250, loss = 0.5463\n",
      "78/100, step 250/250, loss = 0.5242\n",
      "79/100, step 250/250, loss = 0.6152\n",
      "80/100, step 250/250, loss = 0.4556\n",
      "81/100, step 250/250, loss = 0.4273\n",
      "82/100, step 250/250, loss = 0.5429\n",
      "83/100, step 250/250, loss = 0.3309\n",
      "84/100, step 250/250, loss = 0.4431\n",
      "85/100, step 250/250, loss = 0.6182\n",
      "86/100, step 250/250, loss = 0.4899\n",
      "87/100, step 250/250, loss = 0.5748\n",
      "88/100, step 250/250, loss = 0.5087\n",
      "89/100, step 250/250, loss = 0.6430\n",
      "90/100, step 250/250, loss = 0.5148\n",
      "91/100, step 250/250, loss = 0.6118\n",
      "92/100, step 250/250, loss = 0.5148\n",
      "93/100, step 250/250, loss = 0.4774\n",
      "94/100, step 250/250, loss = 0.4619\n",
      "95/100, step 250/250, loss = 0.5023\n",
      "96/100, step 250/250, loss = 0.4868\n",
      "97/100, step 250/250, loss = 0.4277\n",
      "98/100, step 250/250, loss = 0.4871\n",
      "99/100, step 250/250, loss = 0.5399\n",
      "100/100, step 250/250, loss = 0.5714\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterior(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad() # 梯度清零\n",
    "        loss.backward() # 反向传播\n",
    "\n",
    "        # update\n",
    "        optimizer.step() # 更新参数\n",
    "\n",
    "        if (batch_idx+1) % 250 == 0:\n",
    "            print(f\"{epoch+1}/{num_epochs}, step {batch_idx+1}/{len(train_loader)}, loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 加载测试数据\n",
    "with h5py.File('C:/Users/liusi/Desktop/research/transformer/dataset_test.h5', 'r') as f:\n",
    "    test_input_data = f['input_data'][:]  # 假设测试集的特征数据键是 'input_data'\n",
    "    test_labels = f['labels'][:]  # 假设测试集的标签数据键是 'labels'\n",
    "\n",
    "# 2. 创建测试集 Dataset\n",
    "test_dataset = CustomDataset(test_input_data, test_labels)\n",
    "\n",
    "# 3. 创建测试集 DataLoader\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)  # 通常测试集不需要打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss (MSE): 0.5082457321166992\n",
      "Mean Absolute Error (MAE): 0.57504308385849\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "# 计算回归模型性能的指标\n",
    "total_loss = 0.0\n",
    "total_mae = 0.0\n",
    "n_samples = 0\n",
    "\n",
    "model.eval()  # 将模型设置为评估模式\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        outputs = outputs.squeeze()  # 移除单一维度\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterior(outputs, labels)\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # 计算平均绝对误差（MAE）\n",
    "        mae = torch.abs(outputs - labels).mean()\n",
    "        total_mae += mae.item() * images.size(0)\n",
    "\n",
    "        n_samples += images.size(0)\n",
    "\n",
    "# 计算平均损失\n",
    "mean_loss = total_loss / n_samples\n",
    "\n",
    "# 计算平均绝对误差\n",
    "mean_mae = total_mae / n_samples\n",
    "\n",
    "print(f'Mean Loss (MSE): {mean_loss}')\n",
    "print(f'Mean Absolute Error (MAE): {mean_mae}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7041/20000, accuracy = 0.35205\n"
     ]
    }
   ],
   "source": [
    "# 分类问题的测试\n",
    "total = 0\n",
    "correct = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    outputs = model(images)\n",
    "    predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    total += labels.shape[0]\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print(f'{correct}/{total}, accuracy = {correct/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
